# 6.036 Recitation 1: Review

## Dot Product
```
<vec(a), vec(b)> = a^T b
                 = a_1 b_1 + ... a_n b_n
                 = magnitude(vec(a)) * magnitude(vec(b)) * cos(theta)
```

- Projecting vec(b) onto vec(a)
    - scalar projection
        - signed length of AB
            - positive(+) theta is acute, also vec(A) and vec(B) in same direction
            - negative(-) theta is obtuse, also vec(A) and vec(B) in opposite direction
- if vectors are orthogonal, dot_product of them is 0 because cos(theta) term

## Planes

- A plane `P` is uniquely determined by a point `p` and a vector vec(`theta`) orthogonal to `P`
    - Note: orthogonal means orthogonal to every set of planes in `P`

__Equation of a plane__

`P_0 = [1, 2, 3] = [x_0, x_1, x_2] & vec(theta) = [4, 5, 6] = [theta_0, theta_1, theta_2]`

let `P = [x, y, z] for all of P`


__Linear Classifiers__
`transpose(theta) x + thete_0 > 0` is in direction of theta

__Distance between point, p, and plane P__
`P_0 = point on plane, P = plane, p = point, theta = orthogonal to P`
- Distance is shortest between point and plane
    - Shortest is along orthogonal vector to plane
- Do so by projecting `vec(P - P_0) onto theta`
- Signed distance from `p` to `P`
    `( transpose(theta) p + theta_0 ) / magnitiude(vec(theta))`

## Probability

### Gradient
- gradient is a vector
    - vector of partial derivatives of f(x, y, ...)
        - ex: `gradient(f(x,y,z) = transpose(vec([df/dx, df/dy, df/dz]))`
    - this vector points in the direction of the biggest increase in `f(x, y, ...)`

__Example__

`X` = outcome of fair die roll
`X` is a discrete random variable
    - discrete because `X` can only be `[1,2,3,4,5,6]`
`P_x(x) = P[X=x]`
`P_x(x=3) = P[X=3] = 1/6`

__Expectation__
`Expectation[X]` = average value of `X` *not neccesarily a valid value of `X`

### Joint Probability
`P_{x,y}(x, y) = P(X=x AND Y=y)`



### Continuous RVs (Random Variables)
`x` = time til next customer arrives
`f_x(x) = probability density function`
- __PDF__ : probability density function
    - `f_x(x) != P[X=x]` because `P[X=x]` is always 0 *Because its continuous
    - use the pdf when finding the probabiility of range of values for `X=x`
        - integrate `f_x(x)`, the pdf, from `x=a to x=b` to find the `P[X=[a,b]]`
            aka probabilty continuous RV, X, is in range of a and b

probability density function of multiple pdfs is just them multiplied together
if the continuous RVs are independent
